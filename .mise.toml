# pw-mcp task runner configuration
# Run tasks with: mise run <task>

[tools]
python = "3.12"

[env]
PYTHONPATH = "src"

# =============================================================================
# SEMBR - Semantic Line Breaking
# =============================================================================

[tasks.sembr-server]
description = "Start sembr server (loads model once, accepts HTTP requests)"
run = """
uv run sembr --listen -p 8384 -m admko/sembr2023-distilbert-base-multilingual-cased
"""

[tasks.sembr-test]
description = "Test sembr with sample text"
run = """
echo "Stalin implemented the Five-Year Plans. These transformed the Soviet Union." | \
  uv run sembr -m admko/sembr2023-distilbert-base-multilingual-cased
"""

[tasks.sembr-check]
description = "Check if sembr server is running"
run = "uv run pw-ingest sembr --check-only"

[tasks.sembr-process]
description = "Process corpus through sembr (requires sembr-server running)"
run = "uv run pw-ingest sembr -i extracted/ -o sembr/"

[tasks.sembr-sample]
description = "Test sembr with 10 sample files"
run = "uv run pw-ingest sembr -i tests/fixtures/sembr/input/ -o /tmp/sembr-sample/ --sample 5"

# =============================================================================
# CODE QUALITY
# =============================================================================

[tasks.lint]
description = "Run ruff linter"
run = "uv run ruff check src/ tests/"

[tasks.format]
description = "Format code with ruff"
run = "uv run ruff format src/ tests/"

[tasks.typecheck]
description = "Run mypy type checker"
run = "uv run mypy src/pw_mcp/"

[tasks.check]
description = "Run all code quality checks"
depends = ["lint", "typecheck"]

# =============================================================================
# TESTING
# =============================================================================

[tasks.test]
description = "Run all tests"
run = "uv run pytest"

[tasks.test-fast]
description = "Run unit tests only"
run = "uv run pytest -m unit"

[tasks.test-cov]
description = "Run tests with coverage"
run = "uv run pytest --cov"

[tasks.test-integration]
description = "Run integration tests only"
run = "uv run pytest -m integration"

[tasks.test-property]
description = "Run property-based tests"
run = "uv run pytest -m property --hypothesis-profile=dev"

[tasks.test-benchmark]
description = "Run benchmark tests"
run = "uv run pytest -m benchmark --benchmark-only"

[tasks.test-retrieval]
description = "Run retrieval quality tests"
run = "uv run pytest -m retrieval"

# =============================================================================
# PRE-COMMIT
# =============================================================================

[tasks.hooks]
description = "Install pre-commit hooks"
run = "uv run pre-commit install"

[tasks.pre-commit]
description = "Run pre-commit on all files"
run = "uv run pre-commit run --all-files"

# =============================================================================
# PIPELINE STATUS
# =============================================================================

[tasks.status]
description = "Show pipeline status (file counts at each stage)"
run = """
echo "╔══════════════════════════════════════════════════════════════╗"
echo "║                    PIPELINE STATUS                           ║"
echo "╠══════════════════════════════════════════════════════════════╣"
printf "║ %-20s %10s %10s %10s ║\n" "Stage" "Files" "Dir" "Size"
echo "╠══════════════════════════════════════════════════════════════╣"
EXTRACTED=$(find extracted/ -name "*.json" 2>/dev/null | wc -l)
SEMBR=$(find sembr/ -name "*.txt" 2>/dev/null | wc -l)
CHUNKS=$(find chunks/ -name "*.jsonl" 2>/dev/null | wc -l)
EMBEDS=$(find embeddings/ -name "*.npy" 2>/dev/null | wc -l)
EXTRACT_SIZE=$(du -sh extracted/ 2>/dev/null | cut -f1 || echo "N/A")
SEMBR_SIZE=$(du -sh sembr/ 2>/dev/null | cut -f1 || echo "N/A")
CHUNKS_SIZE=$(du -sh chunks/ 2>/dev/null | cut -f1 || echo "N/A")
EMBEDS_SIZE=$(du -sh embeddings/ 2>/dev/null | cut -f1 || echo "N/A")
printf "║ %-20s %10s %10s %10s ║\n" "1. Extracted" "$EXTRACTED" "extracted/" "$EXTRACT_SIZE"
printf "║ %-20s %10s %10s %10s ║\n" "2. Sembr'd" "$SEMBR" "sembr/" "$SEMBR_SIZE"
printf "║ %-20s %10s %10s %10s ║\n" "3. Chunks" "$CHUNKS" "chunks/" "$CHUNKS_SIZE"
printf "║ %-20s %10s %10s %10s ║\n" "4. Embeddings" "$EMBEDS" "embeddings/" "$EMBEDS_SIZE"
echo "╠══════════════════════════════════════════════════════════════╣"
if curl -s http://localhost:8384/check >/dev/null 2>&1; then
  echo "║ Sembr Server: ✓ Running on :8384                            ║"
else
  echo "║ Sembr Server: ✗ Not running (start with: mise run sembr-server) ║"
fi
echo "╚══════════════════════════════════════════════════════════════╝"
"""

# =============================================================================
# PIPELINE STAGES
# =============================================================================

[tasks.extract]
description = "Extract clean text from MediaWiki source files"
run = "uv run pw-ingest extract -i prolewiki-exports/ -o extracted/"

[tasks.extract-sample]
description = "Extract 10 sample files for testing"
run = "uv run pw-ingest extract -i prolewiki-exports/ -o extracted/ --sample 10"

# -----------------------------------------------------------------------------
# Chunking
# -----------------------------------------------------------------------------

[tasks.chunk]
description = "Chunk sembr'd text into embedding-ready segments"
run = "uv run pw-ingest chunk -i sembr/ -o chunks/"

[tasks.chunk-sample]
description = "Chunk 10 sample files for testing"
run = "uv run pw-ingest chunk -i sembr/ -o chunks/ --sample 10"

[tasks.chunk-verbose]
description = "Chunk with verbose logging"
run = "uv run pw-ingest chunk -i sembr/ -o chunks/ --verbose"

# -----------------------------------------------------------------------------
# Embedding
# -----------------------------------------------------------------------------

[tasks.embed]
description = "Generate embeddings (OpenAI by default, set --provider ollama for local)"
run = "uv run pw-ingest embed -i chunks/ -o embeddings/ --provider openai"

[tasks.embed-openai]
description = "Generate embeddings using OpenAI API (requires OPENAI_API_KEY)"
run = "uv run pw-ingest embed -i chunks/ -o embeddings/ --provider openai"

[tasks.embed-ollama]
description = "Generate embeddings using local Ollama server"
run = "uv run pw-ingest embed -i chunks/ -o embeddings/ --provider ollama --model nomic-embed-text"

[tasks.embed-sample]
description = "Embed 10 sample files for testing"
run = "uv run pw-ingest embed -i chunks/ -o embeddings/ --provider openai --sample 10"

[tasks.embed-verbose]
description = "Embed with verbose logging"
run = "uv run pw-ingest embed -i chunks/ -o embeddings/ --provider openai --verbose"

# -----------------------------------------------------------------------------
# ChromaDB Loading
# -----------------------------------------------------------------------------

[tasks.load]
description = "Load chunks and embeddings into ChromaDB"
run = "uv run pw-ingest load --chunks-dir chunks/ --embeddings-dir embeddings/"

[tasks.load-reset]
description = "Clear ChromaDB and reload all data"
run = "uv run pw-ingest load --chunks-dir chunks/ --embeddings-dir embeddings/ --reset"

# =============================================================================
# FULL CORPUS PIPELINE (individual stage commands)
# =============================================================================

[tasks.corpus-status]
description = "Show full corpus pipeline status"
run = """
echo "=== Full Corpus Pipeline Status ==="
printf "%-12s %s files\n" "Source:" "$(find prolewiki-exports -name '*.txt' 2>/dev/null | wc -l)"
printf "%-12s %s files\n" "Extracted:" "$(find extracted -name '*.json' 2>/dev/null | wc -l)"
printf "%-12s %s files\n" "Sembr'd:" "$(find sembr -name '*.txt' 2>/dev/null | wc -l)"
printf "%-12s %s files\n" "Chunks:" "$(find chunks -name '*.jsonl' 2>/dev/null | wc -l)"
printf "%-12s %s files\n" "Embeddings:" "$(find embeddings -name '*.npy' 2>/dev/null | wc -l)"
"""

[tasks.corpus-extract]
description = "Stage 1: Extract articles from MediaWiki markup"
run = "uv run pw-ingest extract -i prolewiki-exports/ -o extracted/"

[tasks.corpus-sembr]
description = "Stage 2: Semantic linebreaking (requires sembr server)"
depends = ["sembr-check"]
run = "uv run pw-ingest sembr -i extracted/ -o sembr/"

[tasks.corpus-chunk]
description = "Stage 3: Chunk sembr'd text into embedding segments"
run = "uv run pw-ingest chunk -i sembr/ -o chunks/"

[tasks.corpus-embed]
description = "Stage 4: Generate embeddings (OpenAI)"
run = "uv run pw-ingest embed -i chunks/ -o embeddings/ --provider openai"

[tasks.corpus-embed-ollama]
description = "Stage 4: Generate embeddings (Ollama local)"
run = "uv run pw-ingest embed -i chunks/ -o embeddings/ --provider ollama"

[tasks.corpus-load]
description = "Stage 5: Load into ChromaDB"
run = "uv run pw-ingest load --chunks-dir chunks/ --embeddings-dir embeddings/"

[tasks.corpus-pipeline]
description = "Run full corpus pipeline: extract → sembr → chunk → embed → load"
run = """
echo "Starting full corpus pipeline..."
echo ""
mise run corpus-status
echo ""
echo "Step 1/5: Extracting from MediaWiki..."
mise run corpus-extract
echo ""
echo "Step 2/5: Semantic linebreaking (requires sembr server)..."
mise run corpus-sembr
echo ""
echo "Step 3/5: Chunking..."
mise run corpus-chunk
echo ""
echo "Step 4/5: Generating embeddings (OpenAI)..."
mise run corpus-embed
echo ""
echo "Step 5/5: Loading into ChromaDB..."
mise run corpus-load
echo ""
mise run corpus-status
echo ""
echo "Full corpus pipeline complete!"
"""

[tasks.corpus-clean]
description = "Clean corpus pipeline output (keep source)"
run = """
rm -rf extracted/ sembr/ chunks/ embeddings/ chroma_data/
mkdir -p extracted/ sembr/ chunks/ embeddings/ chroma_data/
echo "Corpus pipeline cleaned (source preserved)"
"""

# Aliases for backward compatibility
[tasks.pipeline]
description = "Run full pipeline (alias for corpus-pipeline)"
depends = ["corpus-pipeline"]

[tasks.pipeline-sample]
description = "Run pipeline on 10 sample files (for testing)"
run = """
echo "Running sample pipeline (10 files from prolewiki-exports)..."
uv run pw-ingest extract -i prolewiki-exports/ -o extracted/ --sample 10
uv run pw-ingest sembr -i extracted/ -o sembr/ --sample 10
uv run pw-ingest chunk -i sembr/ -o chunks/ --sample 10
uv run pw-ingest embed -i chunks/ -o embeddings/ --provider openai --sample 10
uv run pw-ingest load --chunks-dir chunks/ --embeddings-dir embeddings/
echo "Sample pipeline complete!"
"""

[tasks.pipeline-continue]
description = "Continue pipeline from where it left off (resumes each stage)"
run = """
echo "Continuing pipeline (skipping existing files)..."
mise run sembr-check || { echo "Start sembr server first: mise run sembr-server"; exit 1; }
uv run pw-ingest sembr -i extracted/ -o sembr/
uv run pw-ingest chunk -i sembr/ -o chunks/
uv run pw-ingest embed -i chunks/ -o embeddings/ --provider openai
uv run pw-ingest load --chunks-dir chunks/ --embeddings-dir embeddings/
echo "Pipeline continuation complete!"
"""

# =============================================================================
# GPU & SERVER MANAGEMENT
# =============================================================================

[tasks.gpu-status]
description = "Show GPU status and memory usage"
run = "nvidia-smi --query-gpu=index,name,memory.used,memory.total,utilization.gpu --format=csv"

[tasks.sembr-restart]
description = "Restart sembr server (kills existing, starts fresh)"
run = """
echo "Stopping existing sembr server..."
pkill -f "sembr --listen" 2>/dev/null || true
sleep 2
echo "Starting sembr server..."
uv run sembr --listen -p 8384 -m admko/sembr2023-distilbert-base-multilingual-cased &
sleep 5
if curl -s http://localhost:8384/check >/dev/null 2>&1; then
  echo "Sembr server started successfully"
else
  echo "ERROR: Sembr server failed to start"
  exit 1
fi
"""

[tasks.sembr-stop]
description = "Stop sembr server"
run = """
echo "Stopping sembr server..."
pkill -f "sembr --listen" 2>/dev/null || echo "No sembr server running"
"""

[tasks.sembr-server-gpu1]
description = "Start sembr server on GPU 1 (secondary GPU)"
run = "CUDA_VISIBLE_DEVICES=1 uv run sembr --listen -p 8384"

# =============================================================================
# CLEANUP
# =============================================================================

[tasks.clean-pipeline]
description = "Clean all pipeline output directories"
run = """
echo "Cleaning pipeline output directories..."
rm -rf extracted/ sembr/ chunks/ embeddings/
echo "Pipeline directories cleaned"
"""

[tasks.clean-chroma]
description = "Clean ChromaDB data"
run = """
echo "Cleaning ChromaDB..."
rm -rf chroma_data/
echo "ChromaDB cleaned"
"""

[tasks.clean-all]
description = "Clean everything (pipeline + chroma + build artifacts)"
depends = ["clean-pipeline", "clean-chroma", "clean"]

# =============================================================================
# SAMPLE PIPELINE (distributable demo with public domain works)
# =============================================================================

[tasks.sample-status]
description = "Show sample pipeline status"
run = """
echo "=== Sample Pipeline Status ==="
printf "%-12s %s files\n" "Source:" "$(find sample-pipeline/source -name '*.txt' 2>/dev/null | wc -l)"
printf "%-12s %s files\n" "Extracted:" "$(find sample-pipeline/extracted -name '*.txt' 2>/dev/null | wc -l)"
printf "%-12s %s files\n" "Sembr'd:" "$(find sample-pipeline/sembr -name '*.txt' 2>/dev/null | wc -l)"
printf "%-12s %s files\n" "Chunks:" "$(find sample-pipeline/chunks -name '*.jsonl' 2>/dev/null | wc -l)"
printf "%-12s %s files\n" "Embeddings:" "$(find sample-pipeline/embeddings -name '*.npy' 2>/dev/null | wc -l)"
"""

[tasks.sample-extract]
description = "Extract sample pipeline files (flat directory)"
run = "uv run pw-ingest extract --flat -i sample-pipeline/source -o sample-pipeline/extracted"

[tasks.sample-sembr]
description = "Run sembr on sample files (requires sembr server)"
depends = ["sembr-check"]
run = "uv run pw-ingest sembr -i sample-pipeline/extracted -o sample-pipeline/sembr"

[tasks.sample-chunk]
description = "Chunk sample sembr'd files"
run = "uv run pw-ingest chunk -i sample-pipeline/sembr -o sample-pipeline/chunks"

[tasks.sample-embed]
description = "Generate embeddings for sample chunks (OpenAI)"
run = "uv run pw-ingest embed -i sample-pipeline/chunks -o sample-pipeline/embeddings --provider openai"

[tasks.sample-embed-ollama]
description = "Generate embeddings for sample chunks (Ollama local)"
run = "uv run pw-ingest embed -i sample-pipeline/chunks -o sample-pipeline/embeddings --provider ollama"

[tasks.sample-pipeline]
description = "Run full sample pipeline (requires sembr server)"
run = """
echo "Running sample pipeline..."
mise run sample-extract
mise run sample-sembr
mise run sample-chunk
mise run sample-embed
echo ""
mise run sample-status
echo ""
echo "Sample pipeline complete!"
"""

[tasks.sample-clean]
description = "Clean sample pipeline output (keep source)"
run = """
rm -rf sample-pipeline/extracted sample-pipeline/sembr sample-pipeline/chunks sample-pipeline/embeddings sample-pipeline/chroma_data
mkdir -p sample-pipeline/extracted sample-pipeline/sembr sample-pipeline/chunks sample-pipeline/embeddings sample-pipeline/chroma_data
echo "Sample pipeline cleaned (source preserved)"
"""

# =============================================================================
# MCP SERVER
# =============================================================================

[tasks.serve]
description = "Start the MCP server"
run = "uv run pw-mcp"

# =============================================================================
# DEVELOPMENT
# =============================================================================

[tasks.install]
description = "Install all dependencies including dev"
run = "uv sync --group dev"

[tasks.clean]
description = "Clean build artifacts"
run = """
rm -rf .venv .mypy_cache .ruff_cache .pytest_cache dist build *.egg-info
rm -rf prolewiki-sembr-sample
"""
