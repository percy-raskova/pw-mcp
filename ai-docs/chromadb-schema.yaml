# ProleWiki ChromaDB Schema Definition
# Status: Phase A (MVP) + Phase B (Enriched Metadata) IMPLEMENTED
# Purpose: Contract for what gets loaded into ChromaDB
# Updated: 2025-12-25 - Phase B metadata fields implemented

# =============================================================================
# SCHEMA PHASES
# =============================================================================
# The schema is implemented incrementally to enable MVP delivery while
# preserving the option to add richer metadata later.

schema_phases:
  overview: |
    Phase A: MVP schema - IMPLEMENTED (13 fields from chunker)
    Phase B: Rich metadata - IMPLEMENTED (2025-12-25, 7 additional fields)
    Phase C: Reference metadata - FUTURE (enhance extraction for citations)
    Phase D: Graph metadata - DEFERRED (optional graph computation)

  phase_a:
    name: MVP Schema
    status: IMPLEMENTED
    description: |
      Minimum viable schema for semantic search.
      All fields are output by the chunker (Stage 3).
      Using OpenAI text-embedding-3-large (1536 dimensions).
    fields:
      core:
        - chunk_id        # "{namespace}/{title}#{index}"
        - text            # embedded content (ChromaDB "document")
        - article_title
        - namespace
        - section
        - chunk_index
        - line_range
        - word_count
      article_metadata:
        - categories      # native list
        - internal_links  # native list
        - is_stub
        - citation_needed_count
        - has_blockquote
    total_fields: 13
    source: chunker.py write_chunks_jsonl()
    embedding:
      provider: openai
      model: text-embedding-3-large
      dimensions: 1536

  phase_b:
    name: Rich Metadata
    status: IMPLEMENTED
    implemented_date: 2025-12-25
    description: |
      Propagate already-extracted data from ArticleData to ChromaDB.
      Enables filtering by infobox type, author, political orientation,
      work type, and category-based queries.
    implemented_fields:
      tier_1_mcp_filtering:
        - library_work_author      # IMPLEMENTED - enables "works by X" queries
        - library_work_type        # IMPLEMENTED - Book, Speech, Article, etc.
        - library_work_published_year  # IMPLEMENTED - year extraction from dates
        - infobox_type             # IMPLEMENTED - politician, country, etc.
        - political_orientation    # IMPLEMENTED - ideological filtering
        - primary_category         # IMPLEMENTED - first category for exact match
        - category_count           # IMPLEMENTED - filter by category richness
    future_fields:
      tier_2_biographical:
        - subject_name    # canonical name from infobox
        - birth_year      # for date range queries
        - death_year
        - nationality
        - political_party  # JSON array
      tier_3_provenance:
        - has_foreword
        - source_file
    total_implemented: 7 fields
    total_future: 7 fields
    implementation_files:
      - src/pw_mcp/ingest/cli.py (namespace bug fix - relative paths)
      - src/pw_mcp/ingest/chunker/jsonl_writer.py (Phase B field serialization)
      - src/pw_mcp/db/chroma.py (serialize/deserialize metadata)
    tests_added:
      - tests/unit/chunking/test_chunk_metadata.py (TestExtractYear, extended Phase B tests)
      - tests/unit/db/test_chroma.py (Phase B serialization roundtrip tests)

  phase_c:
    name: Reference Metadata
    status: FUTURE ENHANCEMENT
    description: |
      Citation-derived fields for scholarly content filtering.
      Requires enhancing Stage 1 extraction to link refs to chunks.
      Lower priority than Phase B.
    fields:
      - ref_ids          # references cited in this chunk
      - has_refs         # quick filter for cited content
      - ref_count        # citation density
      - cited_authors    # JSON array of authors
      - cited_years      # JSON array of publication years
      - cited_sources    # JSON array of source names
      - has_quotes       # contains direct quotations
    total_fields: 7 additional
    source: Citations extraction (needs chunk-level linking)

  phase_d:
    name: Graph Metadata
    status: DEFERRED
    description: |
      Derived from optional graph computation.
      Not needed for basic RAG - enhancement for importance ranking.
    fields:
      - backlinks        # JSON array of linking articles
      - backlink_count   # importance metric (PageRank-style)
    total_fields: 2 additional
    source: Graph computation (Stage 6 optional)
    blocking: false

  implementation_order: |
    1. Phase A: Ship with MVP (current chunker output) - DONE
    2. Phase B: Extend chunker for rich metadata - DONE (2025-12-25)
    3. Phase C: When citation-based filtering is needed
    4. Phase D: When importance ranking is needed (optional)

# =============================================================================
# MVP SCHEMA (Phase A) - QUICK REFERENCE
# =============================================================================

mvp_schema:
  description: |
    This is what gets loaded into ChromaDB for MVP.
    Matches exactly what chunker.py write_chunks_jsonl() outputs.
    Embeddings generated via OpenAI text-embedding-3-large (1536 dim).
  collection: prolewiki_chunks
  embedding:
    provider: openai
    model: text-embedding-3-large
    dimensions: 1536

  fields:
    chunk_id:
      type: str
      format: "{namespace}/{title}#{index}"
      example: "Main/Five-Year_Plans#0"
      indexed: true  # ChromaDB ID

    text:
      type: str
      purpose: Embedded content (ChromaDB "document" field)
      max_tokens: ~1000

    article_title:
      type: str
      indexed: true

    namespace:
      type: str
      enum: ["Main", "Library", "Essays", "ProleWiki"]
      indexed: true

    section:
      type: str | null
      indexed: true

    chunk_index:
      type: int
      indexed: true

    line_range:
      type: str
      format: "start-end"
      indexed: false

    word_count:
      type: int
      indexed: true

    categories:
      type: str  # JSON array
      indexed: false

    internal_links:
      type: str  # JSON array
      indexed: false

    is_stub:
      type: bool
      indexed: true

    citation_needed_count:
      type: int
      indexed: true

    has_blockquote:
      type: bool
      indexed: true

  example_record: |
    {
      "chunk_id": "Main/Five-Year_Plans#0",
      "text": "The Five-Year Plans for the National Economy...",
      "article_title": "Five-Year Plans",
      "namespace": "Main",
      "section": null,
      "chunk_index": 0,
      "line_range": "1-45",
      "word_count": 287,
      "categories": ["Soviet economy", "Stalin era"],
      "internal_links": ["Joseph Stalin", "USSR"],
      "is_stub": false,
      "citation_needed_count": 0,
      "has_blockquote": false
    }

# =============================================================================
# FULL SCHEMA REFERENCE (All Phases)
# =============================================================================
# Below is the complete field reference including Phase B/C/D fields.
# Each field is tagged with its phase for clarity.

# =============================================================================
# COLLECTIONS
# =============================================================================

collections:
  # ---------------------------------------------------------------------------
  # PRIMARY COLLECTION: Chunks
  # ---------------------------------------------------------------------------
  prolewiki_chunks:
    purpose: |
      Main searchable collection.
      Each record = one chunk of text with full metadata.
      Supports semantic search + metadata filtering.

    hnsw_config:
      space: cosine
      ef_construction: 200
      ef_search: 100
      # m: 16 (default)

    # -------------------------------------------------------------------------
    # DISTANCE METRIC RATIONALE
    # -------------------------------------------------------------------------
    # ChromaDB HNSW supports three distance metrics:
    #   - cosine: 1 - cos(θ), range 0-2, measures angle between vectors
    #   - l2: Euclidean distance, range 0-∞, measures straight-line distance
    #   - ip: Inner product (negated), range -∞ to ∞, measures projection
    #
    # WHY COSINE?
    #
    # 1. OpenAI embeddings are unit-normalized (||v|| = 1.0 ± 5e-8)
    #    For normalized vectors, ALL THREE METRICS produce IDENTICAL RANKINGS:
    #      L2² = 2(1 - cos_sim)
    #      IP = cos_sim = 1 - cosine_distance
    #    Verified empirically with our embeddings.
    #
    # 2. Cosine is the semantic standard for text:
    #    - Measures "angle between meanings" (direction, not magnitude)
    #    - OpenAI recommends cosine for their embeddings
    #    - Industry standard for NLP/text similarity
    #
    # 3. Interpretable distance values:
    #    - 0.0 = identical (same direction)
    #    - 0.3 = very similar (~85% cosine similarity)
    #    - 0.5 = moderately similar (~75%)
    #    - 1.0 = orthogonal (unrelated)
    #    Compare: L2 would give 0.79 for 0.31 cosine, IP gives -0.69 (confusing)
    #
    # 4. Future-proof:
    #    If we switch to a non-normalized model, cosine still works correctly.
    #    L2/IP would silently give wrong rankings for non-normalized vectors.
    #
    # WHY NOT L2 OR IP?
    #   - L2: Equivalent rankings but less intuitive distance values
    #   - IP: ChromaDB returns negative values (smaller=closer), confusing
    #   - Neither offers any advantage for normalized OpenAI embeddings
    #
    # VERIFIED: Query "Lenin's theory of imperialism" returns identical
    # top-5 rankings with all three metrics (Imperialism#0,#1,#2, Lenin#0,#5)
    # -------------------------------------------------------------------------

    embedding:
      provider: openai
      model: text-embedding-3-large
      dimensions: 1536
      notes: |
        - Configurable dimensions (256-3072), using 1536 for balance
        - API key via OPENAI_API_KEY env var or .env file
        - Cost: ~$0.13 per million tokens

    id_format:
      pattern: "{namespace}/{article_title}#{chunk_index}"
      examples:
        - "Main/Five-Year_Plans#0"
        - "Main/Five-Year_Plans#1"
        - "Library/Capital_Vol_1#127"
        - "Essays/On_Imperialism#3"
      notes: |
        - URL-safe (spaces → underscores)
        - Deterministic for upsert idempotency
        - Sortable by article then chunk order

    fields:
      # -------------------------
      # DOCUMENT (embedded text) - Phase A
      # -------------------------
      document:
        phase: A
        type: str
        purpose: Clean text content of chunk (what gets embedded)
        max_length: ~1000 tokens per chunk
        notes: |
          - MediaWiki markup removed
          - Quotes from references preserved inline
          - Section headers preserved for context
          - Embedded via OpenAI text-embedding-3-large (1536 dim)

      # -------------------------
      # ARTICLE-LEVEL METADATA - Phase A
      # -------------------------
      article_title:
        phase: A
        type: str
        example: "Five-Year Plans"
        indexed: true
        purpose: Group chunks by source article

      namespace:
        phase: A
        type: str
        enum: ["Main", "Library", "Essays", "ProleWiki"]
        indexed: true
        purpose: Filter by content type

      categories:
        phase: A
        type: str  # JSON array
        example: '["Soviet economy", "Stalin era", "Economic planning"]'
        indexed: false  # Use $contains on document or parse JSON
        purpose: Topic classification from [[Category:...]]
        query_pattern: |
          # Filter by category (partial match)
          where_document={"$contains": "Soviet economy"}
          # Or exact category match requires parsing

      internal_links:
        phase: A
        type: str  # JSON array
        example: '["Joseph Stalin", "USSR", "Industrialization"]'
        indexed: false
        purpose: Articles this chunk's article links TO
        notes: Enables "related articles" recommendations

      # -------------------------
      # GRAPH METADATA - Phase D (DEFERRED)
      # -------------------------
      backlinks:
        phase: D
        type: str  # JSON array
        example: '["Marxism–Leninism", "Soviet history"]'
        indexed: false
        purpose: Articles that link TO this chunk's article
        notes: Enables "what links here" queries

      backlink_count:
        phase: D
        type: int
        example: 42
        indexed: true
        purpose: Importance metric (like PageRank)
        query_pattern: |
          # Find "important" articles
          where={"backlink_count": {"$gte": 10}}

      # -------------------------
      # INFOBOX METADATA (article-level) - Phase B
      # -------------------------
      # Extracted from {{Infobox TYPE|...}} templates
      # All chunks from same article share these fields
      # Links within infobox fields are added to internal_links
      # NOTE: Data already extracted in Stage 1, needs chunker extension to serialize

      infobox_type:
        phase: B
        type: str | null
        enum: [politician, country, political_party, person, revolutionary,
               essay, philosopher, company, settlement, military_person,
               organization, guerilla_organization, youtuber, military_conflict,
               book, religion, website, transcript, library_work, null]
        indexed: true
        purpose: What kind of entity this article describes
        examples:
          - politician  # 621 articles
          - country     # 408 articles
          - political_party  # 386 articles
          - person      # 228 articles
        query_pattern: |
          # Find all politician articles
          where={"infobox_type": "politician"}
          # Find articles with any infobox
          where={"infobox_type": {"$ne": None}}

      # --- Biographical fields (people) ---
      subject_name:
        type: str | null
        example: "Mirsaid Sultan-Galiev"
        indexed: true
        purpose: Canonical name from infobox (may differ from article_title)

      native_name:
        type: str | null
        example: "Мирсәет улы Солтангалиев"
        indexed: false
        purpose: Name in original script (Cyrillic, Arabic, Chinese, etc.)

      birth_date:
        type: str | null
        example: "1892-07-13"
        indexed: false
        purpose: ISO date string for birth
        notes: Parsed from {{birth date|Y|M|D}} template

      death_date:
        type: str | null
        example: "1940-01-28"
        indexed: false
        purpose: ISO date string for death

      birth_year:
        type: int | null
        example: 1892
        indexed: true
        purpose: Birth year for range queries
        query_pattern: |
          # Find people born in 19th century
          where={"$and": [
              {"birth_year": {"$gte": 1800}},
              {"birth_year": {"$lt": 1900}}
          ]}

      death_year:
        type: int | null
        example: 1940
        indexed: true
        purpose: Death year for range queries

      birth_place:
        type: str | null
        example: "Elembetyevo, Russian Empire"
        indexed: false
        purpose: Place of birth (links extracted separately)

      death_place:
        type: str | null
        example: "Moscow, Soviet Union"
        indexed: false
        purpose: Place of death

      nationality:
        type: str | null
        example: "Tatar"
        indexed: true
        purpose: Nationality/ethnicity

      death_cause:
        type: str | null
        example: "Assassination"
        indexed: true
        purpose: Cause of death (useful for historical patterns)

      # --- Political/Ideological fields ---
      political_orientation:
        type: str  # JSON array
        example: '["Islamic socialism", "Marxism-Leninism"]'
        indexed: false
        purpose: Ideological classification (HIGHLY valuable for ProleWiki!)
        notes: |
          Extracted from political_orientation, political_line fields.
          Links within values added to internal_links.
        query_pattern: |
          # Find Marxist-Leninist subjects
          where_document={"$contains": "Marxism-Leninism"}

      political_party:
        type: str  # JSON array
        example: '["CPSU", "Arab Socialist Union"]'
        indexed: false
        purpose: Party affiliations
        notes: Multiple parties possible (career changes)

      # --- Organization fields (parties, orgs, countries) ---
      founded_date:
        type: str | null
        example: "1951-06-28"
        indexed: false
        purpose: When organization was founded

      founded_year:
        type: int | null
        example: 1951
        indexed: true
        purpose: Founding year for range queries

      dissolved_date:
        type: str | null
        example: "1981-12-06"
        indexed: false
        purpose: When organization was dissolved

      dissolved_year:
        type: int | null
        example: 1981
        indexed: true
        purpose: Dissolution year

      life_span:
        type: str | null
        example: "1390–1914"
        indexed: false
        purpose: For historical entities (countries, dynasties)

      successor:
        type: str | null
        example: "Party of Democratic Kampuchea"
        indexed: false
        purpose: Successor organization (link extracted)

      predecessor:
        type: str | null
        example: "Indochinese Communist Party"
        indexed: false
        purpose: Predecessor/split-from organization

      # --- Geographic fields (countries, settlements) ---
      capital:
        type: str | null
        example: "Nkumba a Ngudi"
        indexed: false
        purpose: Capital city for countries

      government_type:
        type: str | null
        example: "Elective monarchy"
        indexed: true
        purpose: Form of government

      # --- Essay fields ---
      essay_author:
        type: str | null
        example: "CriticalResist"
        indexed: true
        purpose: ProleWiki username of essay author

      essay_date:
        type: str | null
        example: "2024-03-16"
        indexed: false
        purpose: Publication date of essay

      essay_excerpt:
        type: str | null
        example: "A guide to writing SEO content..."
        indexed: false
        purpose: Short summary/teaser from essay infobox

      # --- Conflict fields ---
      conflict_date:
        type: str | null
        example: "1939-09-01 to 1945-09-02"
        indexed: false
        purpose: Duration of military conflict

      conflict_result:
        type: str | null
        example: "Allied victory"
        indexed: true
        purpose: Outcome of conflict

      # -------------------------
      # LIBRARY WORK METADATA (Library namespace) - Phase B
      # -------------------------
      # Extracted from {{Library work|...}} templates
      # Provides rich bibliographic metadata for Library documents
      # NOTE: Data already extracted in Stage 1, needs chunker extension to serialize

      library_work_title:
        phase: B
        type: str | null
        example: "The CIA's Shining Path: Political Warfare"
        indexed: true
        purpose: Title from Library work template (may differ from article_title)

      library_work_author:
        type: str | null
        example: "Andreo Matías"
        indexed: true
        purpose: Primary author of the work
        notes: Valuable for "works by author" queries

      library_work_type:
        type: str | null
        enum: [Book, Speech, Research paper, Article, Essay, Letter, Pamphlet, null]
        indexed: true
        purpose: Type of library work
        query_pattern: |
          # Find all speeches in Library
          where={"$and": [
              {"namespace": "Library"},
              {"library_work_type": "Speech"}
          ]}

      library_work_published_date:
        type: str | null
        example: "1988"
        indexed: false
        purpose: Publication date (may be year only)

      library_work_published_year:
        type: int | null
        example: 1988
        indexed: true
        purpose: Publication year for range queries

      library_work_source_url:
        type: str | null
        example: "https://es.prolewiki.org/wiki/..."
        indexed: false
        purpose: Source URL for original work

      library_work_translator:
        type: str | null
        example: "ProleWiki"
        indexed: true
        purpose: Who translated the work

      library_work_original_language:
        type: str | null
        example: "Spanish"
        indexed: true
        purpose: Original language before translation
        notes: Valuable for finding translations from specific languages

      library_work_publisher:
        type: str | null
        example: "Documenta Mathematica Series"
        indexed: false
        purpose: Publisher name

      library_work_audiobook_url:
        type: str | null
        example: "https://www.youtube.com/watch?v=..."
        indexed: false
        purpose: Link to audiobook version if available

      # -------------------------
      # CHAPTER NAVIGATION (Library chapters)
      # -------------------------
      # Extracted from {{Book_Navigation|...}} templates
      # Enables reconstruction of book structure

      chapter_previous:
        type: str | null
        example: "Library:Manifesto_of_the_Communist_Party/Conservative or bourgeois socialism"
        indexed: false
        purpose: Link to previous chapter
        notes: Enables "previous chapter" navigation

      chapter_next:
        type: str | null
        example: "Library:Manifesto_of_the_Communist_Party/Position of the communists"
        indexed: false
        purpose: Link to next chapter

      chapter_current:
        type: str | null
        example: "Critical utopian socialism and communism"
        indexed: false
        purpose: Current chapter title

      book_chapters:
        type: str  # JSON array
        example: '["Chapter 1: Introduction", "Chapter 2: Bourgeois and Proletarians"]'
        indexed: false
        purpose: Full chapter list from Book_TOC (for multi-chapter works)

      # -------------------------
      # ARTICLE STATUS FLAGS - Phase A
      # -------------------------
      is_stub:
        phase: A
        type: bool
        example: false
        indexed: true
        purpose: Article marked as incomplete ({{Stub}} template)
        query_pattern: |
          # Exclude stub articles from results
          where={"is_stub": False}
          # Find stubs that need expansion
          where={"is_stub": True}
        notes: May want to lower ranking for stub content in search

      citation_needed_count:
        phase: A
        type: int
        example: 0
        indexed: true
        purpose: Number of {{Citation needed}} markers in article
        query_pattern: |
          # Find well-cited articles (no missing citations)
          where={"citation_needed_count": {"$eq": 0}}
        notes: Higher counts indicate lower editorial quality

      # -------------------------
      # RELATED CONTENT LINKS - Phase B
      # -------------------------
      # NOTE: Needs extraction enhancement or chunker extension
      see_also:
        phase: B
        type: str  # JSON array
        example: '["Daoism", "Legalism"]'
        indexed: false
        purpose: Articles from "See also" section
        notes: |
          High-quality related content indicators.
          Manually curated by editors.

      main_article:
        type: str | null
        example: "Roman Kingdom (753–509 BCE)"
        indexed: false
        purpose: Main article reference from {{Main article}} template
        notes: |
          Indicates "this section summarizes X, see full article"
          Valuable for content relationships

      external_links:
        type: str  # JSON array
        example: '["https://youtube.com/...", "https://archive.org/..."]'
        indexed: false
        purpose: External URLs from "External links" section

      # -------------------------
      # CONTENT FLAGS - Phase A/B
      # -------------------------
      has_blockquote:
        phase: A
        type: bool
        example: true
        indexed: true
        purpose: Chunk contains <blockquote> content
        notes: |
          Blockquotes are often primary source material.
          May want to boost these in search.

      has_foreword:
        phase: B
        type: bool
        example: false
        indexed: true
        purpose: Article has {{Foreword}} content
        notes: Common in Library works with editorial context

      # -------------------------
      # CHUNK-LEVEL METADATA - Phase A
      # -------------------------
      section:
        phase: A
        type: str | null
        example: "Implementation"
        indexed: true
        purpose: Section header this chunk falls under
        notes: null if chunk is before first header

      chunk_index:
        phase: A
        type: int
        example: 0
        indexed: true
        purpose: Order within article (0-indexed)

      line_range:
        phase: A
        type: str
        example: "45-67"
        indexed: false
        purpose: Line numbers in source text for citation
        notes: Format "start-end" (ChromaDB doesn't support tuples)

      word_count:
        phase: A
        type: int
        example: 287
        indexed: true
        purpose: Filter by content density
        query_pattern: |
          # Skip very short chunks
          where={"word_count": {"$gte": 50}}

      # -------------------------
      # REFERENCE-DERIVED METADATA - Phase C
      # -------------------------
      # NOTE: Requires enhancing extraction to link citations to specific chunks
      ref_ids:
        phase: C
        type: str  # JSON array
        example: '["ref:a1b2c3", "ref:d4e5f6"]'
        indexed: false
        purpose: References cited in this chunk
        notes: Links to prolewiki_references collection

      cited_authors:
        type: str  # JSON array
        example: '["Vladimir Lenin", "Karl Marx"]'
        indexed: false
        purpose: Authors cited in this chunk (aggregated from refs)
        query_pattern: |
          # Find chunks citing Lenin
          where_document={"$contains": "Vladimir Lenin"}

      cited_years:
        type: str  # JSON array
        example: '[1909, 1917, 1924]'
        indexed: false
        purpose: Publication years of cited works

      cited_sources:
        type: str  # JSON array
        example: '["Great Soviet Encyclopedia", "Pravda"]'
        indexed: false
        purpose: Publications/sources cited

      has_refs:
        type: bool
        example: true
        indexed: true
        purpose: Quick filter for scholarly content
        query_pattern: |
          where={"has_refs": True}

      ref_count:
        type: int
        example: 3
        indexed: true
        purpose: Citation density metric

      has_quotes:
        type: bool
        example: true
        indexed: true
        purpose: Filter for chunks with direct quotations
        notes: Quotes are often the most semantically rich content

      # -------------------------
      # PROVENANCE - Phase B
      # -------------------------
      source_file:
        phase: B
        type: str
        example: "Main/Five-Year Plans.txt"
        indexed: false
        purpose: Path in prolewiki-exports/ for debugging

  # ---------------------------------------------------------------------------
  # REFERENCE COLLECTION (Optional - Phase C)
  # ---------------------------------------------------------------------------
  # NOTE: Defer until citation-based queries are needed
  prolewiki_references:
    purpose: |
      Normalized reference table.
      Single source of truth for all cited works.
      Enables queries like "all works by Lenin" without scanning chunks.

    hnsw_config: null  # No vector search needed

    embedding: null  # Exact match queries only

    id_format:
      pattern: "ref:{hash}"
      example: "ref:a1b2c3d4e5f6"
      notes: |
        Hash generated from normalized fields:
        - lowercase(authors) + year + lowercase(title)
        - Ensures same work cited differently → same ID

    fields:
      ref_type:
        type: str
        enum: ["citation", "web", "book", "journal", "encyclopedia"]
        indexed: true
        purpose: Type of source

      authors:
        type: str  # JSON array
        example: '["Vladimir Lenin"]'
        indexed: false
        purpose: Author(s) of the work

      year:
        type: int | null
        example: 1909
        indexed: true
        purpose: Publication year

      title:
        type: str
        example: "The Attitude of the Workers' Party to Religion"
        indexed: false
        purpose: Work title

      source_publication:
        type: str | null
        example: "Proletary"
        indexed: true
        purpose: Journal, newspaper, encyclopedia name

      urls:
        type: str  # JSON array
        example: '["https://marxists.org/archive/lenin/works/1909/may/13.htm"]'
        indexed: false
        purpose: All URLs (mia, pdf, archive, etc.)

      citing_articles:
        type: str  # JSON array
        example: '["Main/Atheism", "Main/Religion"]'
        indexed: false
        purpose: Which articles cite this reference
        notes: Enables "cited by" queries

      citation_count:
        type: int
        example: 7
        indexed: true
        purpose: How many articles cite this work

      quotes:
        type: str  # JSON array of quote objects
        example: '[{"text": "Fear made the gods...", "article": "Main/Atheism"}]'
        indexed: false
        purpose: All quotes extracted from this reference

      first_seen_in:
        type: str
        example: "Main/Atheism"
        indexed: false
        purpose: First article where we encountered this ref

# =============================================================================
# METADATA CONSTRAINTS
# =============================================================================

constraints:
  json_arrays: |
    ChromaDB metadata values must be: str, int, float, bool
    Lists stored as JSON strings, parsed on retrieval.
    Query via $contains for partial match.

  string_length: |
    Keep metadata strings reasonable (<1KB each).
    Large arrays (many categories/links) may hit limits.

  null_handling: |
    Use null for missing optional fields.
    ChromaDB supports null in metadata.

  boolean_indexing: |
    Boolean fields are efficient for filtering.
    Use for has_refs, has_quotes type flags.

  numeric_range: |
    Integer fields support $gt, $gte, $lt, $lte.
    Use for word_count, ref_count, backlink_count filtering.

# =============================================================================
# QUERY PATTERNS
# =============================================================================

query_patterns:
  semantic_search:
    description: Basic similarity search
    code: |
      results = collection.query(
          query_embeddings=[embedding],
          n_results=10,
          include=["documents", "metadatas", "distances"]
      )

  search_with_namespace:
    description: Semantic search filtered to Main articles
    code: |
      results = collection.query(
          query_embeddings=[embedding],
          n_results=10,
          where={"namespace": "Main"}
      )

  search_with_citations:
    description: Only return chunks with references
    code: |
      results = collection.query(
          query_embeddings=[embedding],
          n_results=10,
          where={"has_refs": True}
      )

  search_citing_author:
    description: Find chunks citing specific author
    code: |
      results = collection.query(
          query_embeddings=[embedding],
          n_results=10,
          where_document={"$contains": "Vladimir Lenin"}
      )
    notes: Searches in document text; cited_authors is JSON so $contains works

  get_article_chunks:
    description: Retrieve all chunks for an article (in order)
    code: |
      results = collection.get(
          where={"article_title": "Five-Year Plans"},
          include=["documents", "metadatas"]
      )
      # Sort by chunk_index
      sorted_chunks = sorted(
          zip(results["ids"], results["documents"], results["metadatas"]),
          key=lambda x: x[2]["chunk_index"]
      )

  find_related_articles:
    description: Find articles that link to a given article
    code: |
      # Get chunks from articles that link here
      results = collection.get(
          where_document={"$contains": '"Five-Year Plans"'},
          include=["metadatas"]
      )
      # Extract unique article_titles
      related = set(m["article_title"] for m in results["metadatas"])

  important_articles:
    description: Find articles with many backlinks
    code: |
      results = collection.get(
          where={"backlink_count": {"$gte": 20}},
          include=["metadatas"]
      )

  scholarly_content:
    description: Find well-cited chunks
    code: |
      results = collection.query(
          query_embeddings=[embedding],
          n_results=10,
          where={"$and": [
              {"has_refs": True},
              {"ref_count": {"$gte": 2}}
          ]}
      )

  combined_filters:
    description: Complex multi-filter query
    code: |
      results = collection.query(
          query_embeddings=[embedding],
          n_results=10,
          where={"$and": [
              {"namespace": {"$in": ["Main", "Essays"]}},
              {"word_count": {"$gte": 100}},
              {"has_quotes": True}
          ]},
          where_document={"$contains": "imperialism"}
      )

# =============================================================================
# MIGRATION NOTES
# =============================================================================

migration:
  from_scratch: |
    1. Create collections with specified config
    2. Run full pipeline
    3. Batch load chunks
    4. Optionally load references

  incremental: |
    TODO: Design delta update strategy
    - Track file modification times
    - Re-extract changed files only
    - Upsert changed chunks (IDs are deterministic)
    - Update reference citation counts

  schema_changes: |
    Adding new metadata fields:
    - Add to pipeline extraction
    - Existing chunks won't have field (query with default)

    Changing field semantics:
    - Full re-ingestion required
    - Or add new field, deprecate old

# =============================================================================
# OPEN DESIGN QUESTIONS
# =============================================================================

open_questions:
  - question: "Primary category field?"
    status: RESOLVED (2025-12-25)
    resolution: |
      Added both `primary_category` (first category) and `category_count`
      fields to enable exact match filtering and category richness queries.
      The `categories` JSON array is preserved for full category access.

  - question: "Store embeddings in chunks JSONL?"
    context: |
      Currently plan: separate .npy files
      Alternative: base64 embeddings in JSONL
    tradeoffs:
      npy: Smaller files, need to coordinate, efficient numpy ops
      jsonl: Self-contained, larger files, simpler loading

  - question: "Separate references collection worth it?"
    context: |
      prolewiki_references enables ref-specific queries
      but adds complexity. Alternative: just store in chunk metadata.
    recommendation: |
      Start without it. Add later if ref queries are common.

  - question: "Denormalize backlink articles into chunks?"
    context: |
      Currently: backlinks array per chunk
      This duplicates data across chunks of same article.
    options:
      - Keep denormalized (simpler queries)
      - Only store at article level (separate lookup)
    recommendation: |
      Denormalize for now. Storage is cheap, query simplicity wins.
