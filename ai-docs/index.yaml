# AI Documentation Index
# Token-efficient reference files for AI assistants
# Format: YAML for structured lookup, minimal prose

files:
  chromadb.yaml:
    purpose: ChromaDB vector database schema, operations, metadata patterns
    topics:
      - persistence and client setup
      - collection configuration (HNSW, distance metrics)
      - metadata schema and filtering operators
      - batch operations and performance
      - interlinking via metadata (wiki-style relationships)
    use_when:
      - designing database schema
      - implementing ingestion pipeline
      - writing query/search logic
      - optimizing performance

  chromadb-schema.yaml:
    status: Phase A (MVP) IMPLEMENTED - using OpenAI embeddings
    purpose: Concrete ChromaDB schema definition for ProleWiki (phased rollout)
    topics:
      - SCHEMA PHASES (A/B/C/D incremental implementation)
      - MVP SCHEMA (Phase A - 13 fields, ready now)
      - collection definitions (prolewiki_chunks, prolewiki_references)
      - field schemas with types and examples
      - HNSW and embedding configuration
      - ID format patterns
      - metadata constraints (JSON arrays, indexing)
      - query patterns with code examples
      - INFOBOX METADATA (Phase B - biographical, political, organizational fields)
      - LIBRARY WORK METADATA (Phase B - bibliographic fields for Library namespace)
      - REFERENCE METADATA (Phase C - citation-derived fields)
      - GRAPH METADATA (Phase D - backlinks, importance metrics)
      - ARTICLE STATUS FLAGS (Phase A - is_stub, citation_needed_count)
      - CONTENT FLAGS (Phase A/B - has_blockquote, has_foreword)
    sections:
      schema_phases: Phase A/B/C/D definitions with field lists
      mvp_schema: Quick reference for Phase A (13 fields)
      collections: Full field reference tagged by phase
      constraints: ChromaDB metadata limitations
      query_patterns: Common query code examples
      migration: Schema change strategies
      open_questions: Design decisions to resolve
    schema_phases:
      phase_a: MVP - 13 fields already output by chunker
      phase_b: Rich metadata - infobox + library_work (14 fields)
      phase_c: Reference metadata - citations (7 fields)
      phase_d: Graph metadata - backlinks (2 fields) - DEFERRED
    use_when:
      - implementing ChromaDB loading (start with Phase A)
      - writing search/query code
      - reviewing what metadata is available by phase
      - planning schema extensions beyond MVP
      - debugging query results
      - understanding infobox field mappings
      - understanding Library namespace metadata
      - filtering by article quality

  pipeline.yaml:
    status: Stages 1-4 IMPLEMENTED, Stage 5 NEXT
    purpose: Full ingestion pipeline architecture from MediaWiki to ChromaDB
    topics:
      - 5-stage core pipeline (extract → sembr → chunk → embed → load)
      - optional graph computation (backlinks, link counts)
      - intermediate file formats for debuggability
      - CLI interface design
      - INFOBOX EXTRACTION (21 types, field mapping, date parsing, link extraction)
      - ADDITIONAL TEMPLATES (Library work, Book_Navigation, citations, status markers)
    sections:
      stage_1_extraction: MediaWiki parsing + clean_text generation ✓
      stage_1_extraction.infoboxes: |
        Infobox type detection and field extraction
        - 21 infobox types (politician, country, party, etc.)
        - Field mapping (extract vs discard)
        - Date template parsing
        - Link extraction from values
        - Removal from clean_text before sembr
      stage_1_extraction.additional_templates: |
        All other MediaWiki templates beyond infoboxes:
        - {{Library work}} - bibliographic metadata for Library namespace
        - {{Foreword}} - editorial forewords (keep in text)
        - {{Book_Navigation}}, {{Book_TOC}} - chapter navigation
        - {{Main article}} - links to main articles (valuable for graph)
        - {{Stub}}, {{Citation needed}} - article status markers
        - Citation variants (Web, News, Library, Video, YouTube)
        - Display control (DEFAULTSORT, DISPLAYTITLE, TOC limit)
        - Sidebars and navboxes (remove, no extraction)
        - Transclusion markers (noinclude, onlyinclude)
      stage_2_sembr: Semantic linebreaking ✓
      stage_3_chunking: Chunk creation with metadata ✓
      stage_4_embedding: OpenAI text-embedding-3-large (1536-dim) ✓
      stage_5_loading: ChromaDB ingestion
      optional_graph: Backlinks, link counts, category graph (deferred)
      open_questions: Unresolved design decisions
    use_when:
      - planning pipeline implementation
      - understanding data flow
      - debugging intermediate outputs
      - understanding infobox extraction rules
      - understanding graph computation (optional)

  testing-plan.yaml:
    status: DRAFT - ready for implementation
    purpose: Comprehensive testing strategy for RAG database
    topics:
      - test pyramid (unit, integration, E2E)
      - property-based testing with Hypothesis
      - retrieval quality metrics (P@K, MRR, NDCG)
      - performance benchmarks
      - MCP server tests
      - CI/CD configuration
    sections:
      infrastructure: pytest setup, markers, directory structure
      stage_1_extraction_tests: 21 infobox types, citations, links, templates
      stage_2_graph_tests: backlinks, link counts, category graph
      stage_3_cleaning_tests: markup removal, transforms
      stage_4_sembr_tests: server mode, output validation
      stage_5_chunking_tests: token boundaries, metadata attachment
      stage_6_embedding_tests: OpenAI/Ollama provider tests, quality checks
      stage_7_loading_tests: ChromaDB operations, integrity
      integration_tests: cross-stage data flow validation
      retrieval_tests: semantic search quality, filter tests, golden test set
      property_tests: Hypothesis-based parser robustness
      benchmarks: extraction, sembr, embedding, query performance
      mcp_tests: tool tests, protocol compliance, concurrency
      implementation_phases: 4-phase rollout plan
    use_when:
      - setting up test infrastructure
      - writing new tests
      - understanding test coverage requirements
      - configuring CI/CD

  project-status.yaml:
    status: ACTIVE - primary tracking document
    purpose: Track implementation progress and next steps
    topics:
      - implementation phases (8 phases from foundation to fine-tuning)
      - current focus and next actions
      - key decisions made
      - file locations reference
      - useful commands
      - dataclass reference (Link, Citation, InfoboxData, etc.)
    sections:
      phases: All 8 implementation phases with status
      phase_1_foundation: Test infrastructure (COMPLETE)
      phase_2_parsers: TDD Green Phase - parser implementation (COMPLETE)
      phase_3_sembr: Semantic linebreaking integration (COMPLETE)
      phase_4_chunking: Text chunking for embeddings
      phase_5_embedding: Vector embedding generation
      phase_6_loading: ChromaDB ingestion
      phase_7_mcp: MCP server implementation
      phase_8_finetune: Marxist LLM fine-tuning with DeepSeek 7B (PLANNED)
      current_focus: What to work on next
      decisions: Key architectural/process decisions
      key_files: Where everything lives (source_code, type_stubs, tests, fixtures)
      dataclasses: Quick reference for all data types
      useful_commands: Common development commands
    use_when:
      - starting a new session
      - understanding project state
      - deciding what to work on next
      - finding file locations
      - running common commands
    recent_updates:
      - "2025-12-16: Sample pipeline added - 10 public domain works with all outputs committed"
      - "2025-12-16: --flat flag for extract command (namespace from filename prefix)"
      - "2025-12-16: Empty response handling fix for sembr (JSONDecodeError on large files)"
      - "2025-12-16: OpenAI text-embedding-3-large (1536-dim) now primary embedding provider"
      - "2025-12-16: GPU manager + server manager modules for CUDA lifecycle"
      - "2025-12-16: Comprehensive CLI with logging, resume, and progress display"
      - "2025-12-15: PHASE 5.5 - Test fixes + CLI server management (312 tests total)"
      - "2025-12-15: Fixed 4 failing tests (JSON support, graceful errors, concurrency)"
      - "2025-12-15: Added --restart-server/--no-restart CLI flags for CUDA cleanup"
      - "2025-12-15: PHASE 5 COMPLETE - embedding module fully implemented (35 tests)"
      - "2025-12-15: Schema PHASED - Phase A (MVP, 13 fields) ready for implementation"
      - "2025-12-15: PHASE 4 COMPLETE - chunking module + CLI implemented (70 tests)"
      - "2025-12-15: PHASE 3 COMPLETE - sembr integration implemented"
      - "2025-12-14: PHASE 2 COMPLETE - all parsers implemented"

  sembr.yaml:
    status: IMPLEMENTED - Phase 3 complete
    purpose: Complete specification for sembr (semantic linebreaking) integration
    topics:
      - sembr HTTP server protocol (endpoints, request/response formats)
      - linebreaker.py module design (dataclasses, public API)
      - CLI integration (pw-ingest sembr subcommand)
      - mise tasks (sembr-server, sembr-check, sembr-process)
      - testing strategy (unit, integration, slow tests)
      - edge cases (empty input, unicode, long documents)
      - implementation tasks (TDD phases)
      - success criteria (functionality, performance, quality)
    sections:
      overview: Purpose, data flow, why sembr, model info
      server_protocol: HTTP endpoints, request/response formats, performance
      module_design: linebreaker.py classes, exceptions, public API
      cli_integration: pw-ingest sembr subcommand options
      mise_tasks: sembr-server, sembr-check, sembr-process, sembr-sample
      testing_strategy: Test files, fixtures, invariants
      edge_cases: Empty input, unicode, long docs, server unavailable
      implementation_tasks: TDD phases 3.1-3.4
      success_criteria: Functionality, performance, quality targets
    use_when:
      - implementing Phase 3 (sembr integration)
      - understanding sembr server protocol
      - writing sembr tests
      - debugging sembr issues
      - configuring mise tasks
    model_info:
      name: admko/sembr2023-distilbert-base-multilingual-cased
      params: 135M
      languages: [English, Russian, Chinese, Spanish, German, French]
      performance: "~0.2-0.5s/file in server mode vs ~9s/file in CLI mode"

  embedding.yaml:
    status: IMPLEMENTED - Phase 5 COMPLETE (OpenAI provider added)
    purpose: Vector embedding generation for semantic search
    topics:
      - OpenAI text-embedding-3-large (1536-dim, primary)
      - Ollama embeddinggemma (768-dim, local fallback)
      - EmbedConfig with provider selection
      - NPY output format (aligned with JSONL chunk order)
      - CLI integration (pw-ingest embed --provider openai)
      - Testing strategy (~35 tests: unit, CLI, integration)
    sections:
      overview: Goal, input/output, model selection rationale
      model: OpenAI (primary) and Ollama (fallback) specs
      config: EmbedConfig dataclass with provider field
      dataclasses: EmbeddedArticle structure
      public_api: embed_texts, embed_article_chunks, write_embeddings_npy
      openai_integration: API key from .env, retry logic
      ollama_integration: Python library patterns (local fallback)
      output_format: NPY file structure, alignment with chunks
      cli: pw-ingest embed --provider [ollama|openai]
      testing: Test categories, mock strategy, fixtures
    use_when:
      - running embeddings with OpenAI API
      - understanding provider selection
      - writing embedding tests
      - debugging embedding issues
    model_info:
      primary:
        name: text-embedding-3-large
        provider: OpenAI (API)
        dimensions: 1536 (configurable 256-3072)
        cost: ~$0.13 per million tokens
      fallback:
        name: embeddinggemma
        provider: Ollama (local)
        dimensions: 768

  finetune.yaml:
    status: PLANNED - Phase 8 specification
    purpose: Marxist-Leninist LLM fine-tuning on ProleWiki corpus
    topics:
      - DeepSeek 7B base model selection
      - QLoRA configuration via Unsloth framework
      - Q&A data generation from ProleWiki corpus
      - Dataset preparation (Alpaca JSONL format)
      - Training configuration (SFTTrainer)
      - Evaluation strategy (perplexity, manual review)
      - GGUF export for Ollama deployment
    sections:
      overview: Goal, method, hardware requirements
      model: DeepSeek-R1-7B selection and loading code
      qlora_config: LoRA rank, alpha, target modules
      data_generation: Four sources (infobox, section, library, crossref)
      dataset_format: Alpaca JSONL schema and splits
      training_config: SFTTrainer parameters and code
      evaluation: Automated and manual evaluation criteria
      export: GGUF conversion and Ollama integration
      implementation: Five substages (8.1-8.5)
      hardware: GPU requirements and cloud options
      dependencies: Python packages and system requirements
      risks: Data quality, ideological drift, overfitting mitigations
      success_criteria: Quantitative and qualitative targets
    use_when:
      - planning fine-tuning implementation
      - understanding Q&A data generation strategy
      - configuring Unsloth and QLoRA
      - setting up training infrastructure
      - evaluating fine-tuned model
      - deploying to Ollama

  chunking.yaml:
    status: IMPLEMENTED - Phase 4 complete
    purpose: Text chunking for embedding and retrieval
    topics:
      - Chunking algorithm with section/paragraph awareness
      - Token estimation and boundaries (600/200/1000 target/min/max)
      - Metadata propagation from ArticleData
      - JSONL output format for ChromaDB loading
      - CLI integration (pw-ingest chunk subcommand)
      - TDD implementation phases (4.1-4.4) - all complete
    sections:
      design_rationale: Why chunk even with 2048 token limit
      config: ChunkConfig dataclass fields
      dataclasses: Chunk, ChunkedArticle structures
      algorithm: Pseudocode and boundary handling
      output_format: JSONL schema matching chromadb-schema.yaml
      cli: Subcommand options (7 arguments)
      testing: Test structure and categories (70 tests)
      implementation: TDD phases 4.1-4.4 (all COMPLETE)
      success_criteria: Functionality, quality, performance (all met)
    use_when:
      - understanding chunk algorithm
      - writing chunking tests
      - configuring chunk sizes
      - using pw-ingest chunk CLI

# Future entries (add as needed):
# mediawiki.yaml: MediaWiki parsing patterns, template extraction
# mcp.yaml: FastMCP server patterns, tool definitions
